{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e53bf5c7",
      "metadata": {
        "id": "e53bf5c7"
      },
      "source": [
        "# Assignment 2: Implementing Decoding Strategies for Summarization (40 points)\n",
        "\n",
        "In this assignment, you will **implement decoding algorithms** used for text summarization using a pretrained Transformer model.\n",
        "\n",
        "---\n",
        "\n",
        "### Your Task\n",
        "1. **Load** the `sshleifer/distilbart-cnn-12-6` summarization model.\n",
        "2. **Implement the following decoding strategies from scratch** (no `.generate()` allowed!). You need to provide your own explanation on your implementation for each function:\n",
        "   - Greedy decoding (3 points)\n",
        "   - Top-k sampling (3 points)\n",
        "   - Top-p (nucleus) sampling (3 points)\n",
        "   - Beam search (3 points)\n",
        "   - Beam search with n-gram blocking (3 points)\n",
        "3. Use your decoder to summarize 200 articles from the CNN/DailyMail dataset.\n",
        "4. Implement the following ROUGE metrics and evaluate your summaries using your own ROUGE metric implementation.\n",
        "  - Implementation\n",
        "    - ROUGE-n (2 points): e.g., ROUGE-1 & ROUGE-2\n",
        "    - ROUGE-L (4 points)\n",
        "  - Explanation on your implementation (2 points)\n",
        "  - Discuss how to improve these metrics to perform a better evaluation? (2 points)\n",
        "5. Discussion (15 points)\n",
        "\n",
        "---\n",
        "\n",
        "**Note:**\n",
        "  - Regarding the decoding strategies, you are expected to work directly with model logits and sampling logic. Do not use `model.generate()` or any pre-built function. **Hint**: use \"outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\"\n",
        "  - For each function, you need to write clear and concise comments about your implementation. This may not be line-by-line, but rather meaningful chunk of codes.\n",
        "  - For each question, justify your answer with explanations.\n",
        "\n",
        "### **We highly recommend using 'cpu' as the default for development, and switching to 'gpu' only for evaluating summarization performance. This is due to the limited GPU availability in the Colab environment.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f3b788c8",
      "metadata": {
        "id": "f3b788c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4c1d46-a075-4026-b693-055d88d930dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m481.3/491.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f2b0b6c5",
      "metadata": {
        "id": "f2b0b6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "749a0522c1c34568b4778ee9b4d5e925",
            "3699e1cd564a460aa5798203bf0dbf4c",
            "b98cbc3fa01a41a2bef3882f38282908",
            "43ace8dbb2634c238d9e2836f81862fb",
            "d83cac04ca7f4f2eac6c8df34aa6438d",
            "f2ea58bd63fb4f77a28fb5f714250216",
            "cd057e63c14647c18def63fc21ac20a5",
            "c64b0aaa63674237b4b658738e5b6e40",
            "af4fd2fa135642bf9788f200cb4f2044",
            "4fffce4414ed4edb93b46f41313400af",
            "111ccf9331af43fdbfa555a44f8b5966",
            "d1c438c833c7425eb794e841536cc8fc",
            "f3d4c97f581a408bbbea1980a30af7e2",
            "d4cc3bb1348647c9abfceaa6daefe402",
            "cde08c3584a94499949bc6ef384555ab",
            "70007bda0210464083f13bae67d0257e",
            "25c5b5c7ee104737bdcdb493edb3a115",
            "792c5b72236c45fd9eec5524c15c1887",
            "49c6119f525a4173bbb5533ce21bf9ec",
            "4e8bff68f97c4228b87de21cd5c59d28",
            "13ac1ef272a947b4a6bc353db894d443",
            "c1f7c88ae0964244b2da491ca05ba1b6",
            "fc612ae5248e420eb101dfae477c1a07",
            "d0dec88f3d4040d59b7dce138f5f9fb1",
            "993a35aaac574fc6863a54524b391021",
            "e550b62690f5493191cc805c56792afb",
            "4b5a99e5c72d446a9e44a08a2c59b675",
            "e0d5651ea0ff4e01acd6e0d67baec6fd",
            "efeba7acaf2640ee8941c6e448d136db",
            "3dd76ef8911f48c3bb4e794b42f50582",
            "805f5ca2afb54b2aa76d76e27ec2a851",
            "723a09f57c0f4284a69a2bf00dfc09c1",
            "8f2da236c7ca4c4298a89f3bde86487a",
            "a2563dda79564d08a9fa9f7a1029cfb6",
            "9eb8c5f6da52484387994a30dfa5fb71",
            "fa50a74c62794b07bc4c818817aad479",
            "a9569443d155484fbaa63d767e1aef12",
            "46da4dea9b32451c99a3c942e419b400",
            "d804173162b4468ebe7f3a6dd4e9ec7b",
            "59afbb47d7b24f5f9db20dfcf83540cf",
            "2e30752ab6fe4f29a3953244574be804",
            "f0871a0275134a40b0dbabc78bce7cbe",
            "8d0e5b0584f745c6b132998d282afa70",
            "ed6ba303ca4544d98252dbf8270709ee",
            "b6313a4351314a0ca290ffb185cd5150",
            "a32ddd204f4e4cc394863ea3db2028a3",
            "44bf1ac378ee4e72b84a9e11c6d786b9",
            "6fc8b88fde304e17b094bbbf293c7d37",
            "724963811439426b9dda30511a622a48",
            "21c5516c496f434da02348602199d5f6",
            "062033d7c99c4418b41d91aac370bc6e",
            "139c982e3b194c9dba36504eb3db951b",
            "e876de1284a54e83a15d99aa5137ab85",
            "114732ed2c064e4a8ea3dcc8bc44355c",
            "70103858f17a424789683d4a1238e170",
            "ecef1ac1e57f4188b9c91d2f7a2c4d87",
            "3812d1f7b27e4dfc87f0283aba0ea5b0",
            "bc5fed263ec64fb7a6aed3195e9e9cfa",
            "ec5b9ea0374f48e2b5e1f2689a735f67",
            "58a5f12854b24ec382ff4d998fe21974",
            "59a7f6782e8541ec8a19a4b76f88d34c",
            "2a8cc7eb126b473aac197a969e51576e",
            "5fb393e638c444d99fe4cdfa8323e7af",
            "da20b564781547d896dfe47bafbadc65",
            "c15ee039d17d4f06ad47f07ae1efea37",
            "68bbf87091944903b882798cea4bd3e3"
          ]
        },
        "outputId": "a7611ace-ea5c-41bb-a581-20edde057726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "749a0522c1c34568b4778ee9b4d5e925"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1c438c833c7425eb794e841536cc8fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc612ae5248e420eb101dfae477c1a07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2563dda79564d08a9fa9f7a1029cfb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6313a4351314a0ca290ffb185cd5150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecef1ac1e57f4188b9c91d2f7a2c4d87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "# load model to gpu for faster inference\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71208984",
      "metadata": {
        "id": "71208984"
      },
      "source": [
        "In this assignment, we use the CNN/DailyMail summarization dataset, a widely-used benchmark for training and evaluating text summarization models.\n",
        "\n",
        "Each data sample consists of:\n",
        "\n",
        "- article: A news story, usually between 300 and 800 words.\n",
        "\n",
        "- highlights: A bullet-style abstractive summary of the article, written by human editors.\n",
        "\n",
        "This dataset is ideal for testing decoding strategies because:\n",
        "\n",
        "- The summaries are relatively short and factual\n",
        "\n",
        "- The dataset is large enough to support diverse decoding behavior\n",
        "\n",
        "- It has been used in many summarization papers, making ROUGE scores easy to compare\n",
        "\n",
        "In this assignment, we will use a small subset of 200 samples from the validation set for quick experimentation and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a1d2d74e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1d2d74e",
        "outputId": "32055353-3ad7-486c-be29-80194e3dfc75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 samples.\n",
            "\n",
            "Example article:\n",
            "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday's ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court's treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What's objectionable is the attempts to undermine international justice, not Palestine's decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court's decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN's Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.\n",
            "\n",
            "Reference summary:\n",
            "Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n"
          ]
        }
      ],
      "source": [
        "# Upload cnn_dm_200.json file\n",
        "\n",
        "# Load 200-sample dataset\n",
        "with open(\"cnn_dm_200.json\", \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(dataset)} samples.\")\n",
        "print(\"\\nExample article:\")\n",
        "print(dataset[0][\"article\"])\n",
        "print(\"\\nReference summary:\")\n",
        "print(dataset[0][\"highlights\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491ce644",
      "metadata": {
        "id": "491ce644"
      },
      "source": [
        "## Decoding in Language Models\n",
        "Pretrained language models like BART or GPT generate text by predicting the most likely next token one at a time.\n",
        "However, simply choosing the most probable token at each step often leads to deterministic, repetitive, or generic outputs.\n",
        "\n",
        "To overcome this, several decoding strategies have been proposed to balance:\n",
        "\n",
        "- fluency vs. diversity\n",
        "\n",
        "- coherence vs. novelty\n",
        "\n",
        "In this assignment, you will implement five widely-used decoding strategies from scratch and compare their effects."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75e0c151",
      "metadata": {
        "id": "75e0c151"
      },
      "source": [
        "### Greedy Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "42d72411",
      "metadata": {
        "id": "42d72411"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(input_ids, max_length=128):\n",
        "    \"\"\"\n",
        "    Perform greedy decoding from the model using logits.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Greedy Decoding from scratch\n",
        "    input_ids = input_ids.to(device) # load model to device\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "\n",
        "    for _ in range(max_length):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "        proba_output = torch.softmax(output.logits[:,-1,:],axis=-1) # take the last token logits and apply softmax to get the probability of each token\n",
        "        id = torch.tensor([[torch.argmax(proba_output, axis=-1)]]).to(device) # greedy approach to take the token_id with largest probability\n",
        "        decoder_input_ids = torch.cat([decoder_input_ids,id],axis=-1) # append the decoded token to the generated token sequence\n",
        "\n",
        "        if id.item() == eos_token_id: # If the model generate an EOS token, the decoding process should be stop\n",
        "            break\n",
        "\n",
        "    summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True) # convert the generated token sequence to string\n",
        "\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AW2YSwP3PGcn",
      "metadata": {
        "id": "AW2YSwP3PGcn"
      },
      "source": [
        "Explain your implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0b256c",
      "metadata": {
        "id": "ed0b256c"
      },
      "source": [
        "My implementation performs greedy decoding for a sequence-to-sequence model by iteratively generating tokens based on the highest probability prediction at each step. Firstly, it inputs a decoder start token id to start auto-regressive process. The model takes in decoder start token id and returns logits for next token. The softmax function is applied to convert logits to probabilites, and the token id, which is the index in the tensor, is chosen with respect to the highest probability. The chosen token id is then concatenated with the sequence of previously generated tokens, to feed back into the model for the next iteration. The process stop until model outputs the end of sentence token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba10a34",
      "metadata": {
        "id": "dba10a34"
      },
      "source": [
        "### Top-k Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "22a1957b",
      "metadata": {
        "id": "22a1957b"
      },
      "outputs": [],
      "source": [
        "def top_k_decode(input_ids, k=2, max_length=128, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Perform Top-k sampling decoding from the model.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        k (int): Number of top tokens to sample from.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "        temperature (float): Softmax temperature for sampling.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Top-k Sampling Decoding\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      with torch.no_grad():\n",
        "        output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "      output_proba = torch.softmax(output.logits[:,-1,:]/temperature,axis=-1) # convert logits to probability, devide by the temperature to control the randomness and shape of probability distribution\n",
        "      values, indices = torch.topk(output_proba, k=k, axis=-1) # take top k tokens with largest probability\n",
        "      values = values/ torch.sum(values,axis=-1,keepdim=True).item() # redistribute probability of selected tokens, made them summing up to 1\n",
        "      local_index = torch.multinomial(values[0],num_samples=1) # sampling from redistributed probability distribution\n",
        "      id = indices[:,local_index] # take the token id of the sampled token\n",
        "      decoder_input_ids = torch.cat([decoder_input_ids,id],axis=-1) # add the sampled token to the generated token sequence\n",
        "\n",
        "      if id.item() == eos_token_id: # If the model generate an EOS token, the decoding process should be stop\n",
        "        break\n",
        "\n",
        "    summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True) # convert the generated token sequence to string\n",
        "    return summary\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oyFRQsTiPWHn",
      "metadata": {
        "id": "oyFRQsTiPWHn"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa8530e",
      "metadata": {
        "id": "0aa8530e"
      },
      "source": [
        "- My implementation of top-k sampling involves selecting the top k most probable tokens from the model's output logits at each decoding step. The logits are first converted to probabilities using the softmax function. Then, use torch.topk function to select k indices with largest probabilities. Then, the probabilities of k selected tokens must be redistributed to have sum of 1. After that, I sample a token using torch.multinomial function to sample elements from a given probability distribution. This process is repeated until an end-of-sequence token is generated or a maximum length is reached.\n",
        "- The hyperparameter k determines the number of top tokens to consider for sampling. A smaller k leads to more deterministic outputs, as fewer options are available, while a larger k increases diversity but may introduce noise. If k is set too high, the model may generate less coherent or relevant text, as it has too many options to choose from. Conversely, if k is too low, the generated text may become repetitive or lack variety. If k is set to 1, top k sampling becomes equivalent to greedy decoding, as only the most probable token is selected at each step.\n",
        "- The hyperpatameter temperature is used to control the randomness of the sampling process. A lower temperature results in more conservative and deterministic outputs, while a higher temperature increases diversity but may lead to less coherent text. If the temperature is set to 1, it means no scaling is applied to the logits, and the sampling process behaves as if it were using the original probabilities. If we increase the temperature, the probabilities distribution becomes more uniform. In contrast, we reduce the temperature, the distribution becomes sharper."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06aad60",
      "metadata": {
        "id": "b06aad60"
      },
      "source": [
        "### Top-p Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fe9c4772",
      "metadata": {
        "id": "fe9c4772"
      },
      "outputs": [],
      "source": [
        "def top_p_decode(input_ids, p=0.9, max_length=128, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Perform Top-p (nucleus) sampling decoding from the model.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        p (float): Cumulative probability threshold for sampling.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "        temperature (float): Softmax temperature for sampling.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Top-p Sampling Decoding\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      with torch.no_grad():\n",
        "        output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "      output_proba = torch.softmax(output.logits[:,-1,:]/temperature,axis=-1)[0] # convert logits to probability, devide by the temperature to control the randomness and shape of probability distribution\n",
        "      sorted_probs, sorted_indices = torch.sort(output_proba, descending=True) # sort the probabilites and their corresponding token ids\n",
        "      cumulative_probs = torch.cumsum(sorted_probs, dim=0) # calculate the cumulative probability\n",
        "      nucleus_mask = cumulative_probs <= p # create a mask for the tokens that are below the threshold\n",
        "      nucleus_mask[max((cumulative_probs > p).nonzero(as_tuple=True)[0][0], 0)] = True # Ensure we include at least one token after passing threshold\n",
        "      nucleus_probs = sorted_probs[nucleus_mask] # filter the probabilities based on the mask\n",
        "      nucleus_indices = sorted_indices[nucleus_mask] # filter the token ids based on the mask\n",
        "      nucleus_probs = nucleus_probs/torch.sum(nucleus_probs) # redistribute the probabilities of the selected tokens\n",
        "      local_index = torch.multinomial(nucleus_probs,num_samples=1) # sampling from redistributed probability distribution\n",
        "      id = torch.tensor([[nucleus_indices[local_index]]]).to(device)\n",
        "      decoder_input_ids = torch.cat([decoder_input_ids,id],axis=-1)\n",
        "\n",
        "      if id.item() == eos_token_id: # If the model generate an EOS token, the decoding process should be stop\n",
        "        break\n",
        "\n",
        "\n",
        "    summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ynhylQrWPXJi",
      "metadata": {
        "id": "ynhylQrWPXJi"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081cae83",
      "metadata": {
        "id": "081cae83"
      },
      "source": [
        "- My implementation of top-p (percentile) decoding is different from top-k sampling in that: It selects the smallest set of tokens whose cumulative probability exceeds a threshold p. The logits are first devided by temperature to control the shape of distribution and converted to probabilities using the softmax function. Then, I sort the probabilities in descending order and compute the cumulative sum. I select the smallest set of tokens such that their cumulative probability is greater than or equal to p, implemented by using masks for filtering in tensor. After that, the probabilities of selected candidates must be redistributed to sum up 1. Afterwards, I sample a token from this set and the remaining process is similar to the top-k sampling method. This process is repeated until an end-of-sequence token is generated or a maximum length is reached.      \n",
        "- The hyperparameter p determines the threshold for cumulative probability. A smaller p leads to more deterministic outputs, as fewer options are available, while a larger p increases diversity but may introduce noise. If p is set too high, the model may generate less coherent or relevant text, as it has too many options to choose from. Conversely, if p is too low, the generated text may become repetitive or lack variety.\n",
        "- The hyperpatameter temperature is used to control the randomness of the sampling process. A lower temperature results in more conservative and deterministic outputs, while a higher temperature increases diversity but may lead to less coherent text. If the temperature is set to 1, it means no scaling is applied to the logits, and the sampling process behaves as if it were using the original probabilities. If we increase the temperature, the probabilities distribution becomes more uniform. In contrast, we reduce the temperature, the distribution becomes sharper.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b274b9f",
      "metadata": {
        "id": "2b274b9f"
      },
      "source": [
        "### Beam Search Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f9fa0a79",
      "metadata": {
        "id": "f9fa0a79"
      },
      "outputs": [],
      "source": [
        "def beam_search_decode(input_ids, beam_size=4, max_length=128):\n",
        "    \"\"\"\n",
        "    Perform beam search decoding from the model.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        beam_size (int): Number of beams to explore.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Beam Search Decoding\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "    vocab_size = model.config.vocab_size # take the vocab size from the model config\n",
        "\n",
        "    top_beam = [] # to store top k beams with highest probability at each step\n",
        "    with torch.no_grad():\n",
        "      output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "\n",
        "    output_proba = torch.softmax(output.logits[:,-1,:],axis=-1)\n",
        "    probas, indices = torch.topk(output_proba,k=beam_size,axis=-1) # select top k tokens with largest probability, called beams in the first step\n",
        "    for index,proba in zip(indices[0],probas[0]):\n",
        "      top_beam.append((torch.tensor([[decoder_input_ids,index]]),proba.item())) # append top k beams to the list to start the beam search process\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      beam_list = [] # beam list to store all the beams, total number of beams in comparison will be beam_size * vocab_size\n",
        "      for beam in top_beam:\n",
        "        with torch.no_grad():\n",
        "          output = model(input_ids=input_ids, decoder_input_ids=beam[0]).logits[:,-1,:]\n",
        "        output_proba = beam[1] * torch.softmax(output,axis=-1) # calculate the cumulative probability by multiplying the probability of the current beam with the conditional probability of the next token\n",
        "        for idx,local_proba in enumerate(list(output_proba[0])):\n",
        "          beam_list.append((torch.cat([beam[0],torch.tensor([[idx]])],axis=-1), local_proba.item())) # append each candidate to the beam list, the candidate is the current beam with the next token id appended to it\n",
        "\n",
        "      sorted_beam_list = sorted(beam_list, key=lambda item: item[1], reverse=True) # sort the beam list based on the cumulated probability for later selection\n",
        "      top_beam = sorted_beam_list[:beam_size] # select top k beams with largest probability\n",
        "\n",
        "      if top_beam[0][0][0][-1].item() == eos_token_id:\n",
        "        break\n",
        "\n",
        "    summary = tokenizer.decode(top_beam[0][0][0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H36U-rVaPYBQ",
      "metadata": {
        "id": "H36U-rVaPYBQ"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc8d94b",
      "metadata": {
        "id": "bdc8d94b"
      },
      "source": [
        "- My implementation of beam search decoding involves maintaining a fixed number of candidate sequences (beams) at each decoding step. The process starts with the decoder start token id and iteratively expands each beam by generating the next token probabilities. For each beam, I compute the probabilities of all possible next tokens and select the top k beams based on their cumulative probabilities. This is done using append all possible beams to the list and sorted based on their probabilities. The process continues until an end-of-sequence token is generated and is selected as the highest probable beam or a maximum length is reached.\n",
        "- The hyperparameter k (beam width) determines the number of candidate sequences to maintain at each step. A larger k increases the search space and may result in more diverse output as it can explore beam with higher probability. This may leads to more coherent outputs, but also increases computational cost. A smaller k reduces the search space and may lead to less diverse outputs. If k is set to 1, beam search becomes equivalent to greedy decoding, as only the most probable sequence is selected at each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72276cb9",
      "metadata": {
        "id": "72276cb9"
      },
      "source": [
        "### Beam Search with N-gram Blocking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cacdfda9",
      "metadata": {
        "id": "cacdfda9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def isBlocked(token_seq: list(), no_repeat_ngram_size: int, next_token: int):\n",
        "  '''\n",
        "  This function checks if the next token is blocked by the n-gram repetition blocking rule.\n",
        "  It iteratively check if the next token is in the last n-gram size of the token sequence.\n",
        "  '''\n",
        "  if len(token_seq) < no_repeat_ngram_size:\n",
        "    return False\n",
        "  candidate_seq = token_seq[-(no_repeat_ngram_size-1):] + [next_token]\n",
        "\n",
        "  for i in range(len(token_seq)-(no_repeat_ngram_size-1)):\n",
        "    ref_seq = token_seq[i: i+ no_repeat_ngram_size]\n",
        "    if ref_seq == candidate_seq:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def beam_search_ngram_block(input_ids, beam_size=4, max_length=128, no_repeat_ngram_size=3):\n",
        "    \"\"\"\n",
        "    Perform beam search decoding with n-gram repetition blocking.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        beam_size (int): Number of beams to explore.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "        no_repeat_ngram_size (int): Size of n-gram to prevent from repeating.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Beam Search with n-gram blocking\n",
        "\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device)\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "    vocab_size = model.config.vocab_size # take the vocab size from the model config\n",
        "\n",
        "    top_beam = []\n",
        "    with torch.no_grad():\n",
        "      output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids).logits[:,-1,:]\n",
        "    output_proba = torch.softmax(output,axis=-1)\n",
        "    probas, indices = torch.topk(output_proba,k=beam_size,axis=-1)\n",
        "    for index,proba in zip(indices[0],probas[0]):\n",
        "      top_beam.append((torch.tensor([[decoder_input_ids,index]]),proba.item()))\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      beam_list = []\n",
        "      for beam in top_beam:\n",
        "        with torch.no_grad():\n",
        "          output = model(input_ids=input_ids, decoder_input_ids=beam[0].to(device))\n",
        "        output = output.logits[:,-1,:]\n",
        "        output_proba = beam[1] * torch.softmax(output,axis=-1)\n",
        "        for idx,local_proba in enumerate(list(output_proba[0])):\n",
        "          if not isBlocked(token_seq=beam[0][0].tolist(),no_repeat_ngram_size=no_repeat_ngram_size,next_token=idx): # check if the next token is blocked by the n-gram repetition blocking rule before being added to the beam list\n",
        "            beam_list.append((torch.cat([beam[0],torch.tensor([[idx]])],axis=-1), local_proba.item()))\n",
        "      sorted_beam_list = sorted(beam_list, key=lambda item: item[1], reverse=True)\n",
        "      top_beam = sorted_beam_list[:beam_size]\n",
        "\n",
        "      if top_beam[0][0][0][-1].item() == eos_token_id:\n",
        "        break\n",
        "\n",
        "    summary = tokenizer.decode(top_beam[0][0][0], skip_special_tokens=True)\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hBw-4rWiPZTm",
      "metadata": {
        "id": "hBw-4rWiPZTm"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88fcc4a",
      "metadata": {
        "id": "b88fcc4a"
      },
      "source": [
        "- My implementation for beam search with n-gram blocking is almost similar to the implementation of beam search decoding, except the checking of valid beams. before the candidate beam is added to the list, it should be checked if it creates n-grams that are already present in the previous beams. If it does, it is discarded.\n",
        "- The hyperparameter n (no_repeat_ngram_size) determines the size of the n-grams to block. A larger n leads to less aggressive blocking as only large n-grams are blocked, allowing short repetition. A smaller n avoids more repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4cecd13",
      "metadata": {
        "id": "e4cecd13"
      },
      "outputs": [],
      "source": [
        "# Example usage with the above decoding functions\n",
        "input_text = dataset[0]['article']\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
        "\n",
        "print(\"Greedy Search:\")\n",
        "print(greedy_decode(input_ids))\n",
        "\n",
        "print(\"\\nTop k decoding:\")\n",
        "print(top_k_decode(input_ids))\n",
        "\n",
        "print(\"\\nTop p decoding:\")\n",
        "print(top_p_decode(input_ids))\n",
        "\n",
        "print(\"\\nBeam search decoding:\")\n",
        "print(beam_search_decode(input_ids))\n",
        "\n",
        "print(\"\\nBeam Search + N-gram Blocking:\")\n",
        "print(beam_search_ngram_block(input_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fe1341",
      "metadata": {
        "id": "25fe1341"
      },
      "source": [
        "## ROUGE Metric Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bacaa3b",
      "metadata": {
        "id": "4bacaa3b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def compute_rouge_n(reference: str, generated: str, n: int = 1) -> dict:\n",
        "    \"\"\"\n",
        "    Compute ROUGE-N score between reference and generated text.\n",
        "\n",
        "    Args:\n",
        "        reference (str): The reference summary.\n",
        "        generated (str): The generated summary.\n",
        "        n (int): The n-gram size (e.g., 1 for ROUGE-1).\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with 'precision', 'recall', and 'f1' scores.\n",
        "    \"\"\"\n",
        "    ref_tokens = tokenize(reference)\n",
        "    gen_tokens = tokenize(generated)\n",
        "\n",
        "    ref_ngrams = Counter([tuple(ref_tokens[i:i+n]) for i in range(len(ref_tokens)-n+1)])\n",
        "    gen_ngrams = Counter([tuple(gen_tokens[i:i+n]) for i in range(len(gen_tokens)-n+1)])\n",
        "\n",
        "\n",
        "    overlap = sum((ref_ngrams & gen_ngrams).values())\n",
        "\n",
        "    precision = overlap / sum(gen_ngrams.values()) if gen_ngrams else 0.0\n",
        "    recall = overlap / sum(ref_ngrams.values()) if ref_ngrams else 0.0\n",
        "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "def lcs(X, Y):\n",
        "    \"\"\"\n",
        "    Helper function to compute the length of Longest Common Subsequence (LCS)\n",
        "    \"\"\"\n",
        "    m, n = len(X), len(Y)\n",
        "    dp = [[0] * (n+1) for _ in range(m+1)]\n",
        "\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            if X[i] == Y[j]:\n",
        "                dp[i+1][j+1] = dp[i][j] + 1\n",
        "            else:\n",
        "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
        "    return dp[m][n]\n",
        "\n",
        "def compute_rouge_l(reference: str, generated: str) -> dict:\n",
        "    \"\"\"\n",
        "    Compute ROUGE-L (Longest Common Subsequence) score.\n",
        "\n",
        "    Args:\n",
        "        reference (str): The ground truth summary.\n",
        "        generated (str): The generated summary by the model.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with precision, recall, and f1 scores.\n",
        "    \"\"\"\n",
        "    ref_tokens = tokenize(reference)\n",
        "    gen_tokens = tokenize(generated)\n",
        "\n",
        "    lcs_len = lcs(ref_tokens, gen_tokens)\n",
        "\n",
        "    precision = lcs_len / len(gen_tokens) if gen_tokens else 0.0\n",
        "    recall = lcs_len / len(ref_tokens) if ref_tokens else 0.0\n",
        "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WRupJH9OPdqJ",
      "metadata": {
        "id": "WRupJH9OPdqJ"
      },
      "source": [
        "- Explanation on your implementation\n",
        "- Discuss how to improve these metrics to perform a better evaluation?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "105bd846",
      "metadata": {
        "id": "105bd846"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f2f8f57",
      "metadata": {
        "id": "6f2f8f57"
      },
      "outputs": [],
      "source": [
        "def generate_summary_custom(article_text, strategy=\"greedy\"):\n",
        "    input_ids = tokenizer(article_text, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
        "    if strategy == \"greedy\":\n",
        "        return greedy_decode(input_ids)\n",
        "    elif strategy == \"top_k\":\n",
        "        return top_k_decode(input_ids)\n",
        "    elif strategy == \"top_p\":\n",
        "        return top_p_decode(input_ids)\n",
        "    elif strategy == \"beam\":\n",
        "        return beam_search_decode(input_ids)\n",
        "    elif strategy == \"beam_block\":\n",
        "        return beam_search_ngram_block(input_ids)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown decoding strategy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbbb0f60",
      "metadata": {
        "id": "fbbb0f60"
      },
      "outputs": [],
      "source": [
        "# Compare summaries across all decoding strategies for one article\n",
        "sample_article = dataset[0][\"article\"]\n",
        "for strategy in [\"greedy\", \"top_k\", \"top_p\", \"beam\", \"beam_block\"]:\n",
        "    print(f\"\\n[{strategy.upper()}]\")\n",
        "    print(generate_summary_custom(sample_article, strategy=strategy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RK_9phseyjdx",
      "metadata": {
        "id": "RK_9phseyjdx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Decoding strategies\n",
        "strategies = [\"greedy\", \"top_k\", \"top_p\", \"beam\", \"beam_block\"]\n",
        "\n",
        "# Save evalution results\n",
        "results = {s: [] for s in strategies}\n",
        "\n",
        "# Evaluation loop\n",
        "for i, sample in enumerate(dataset):\n",
        "    article = sample[\"article\"]\n",
        "    reference = sample[\"highlights\"]\n",
        "\n",
        "    input_ids = tokenizer(article, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
        "\n",
        "    for strategy in strategies:\n",
        "        try:\n",
        "            generated = generate_summary_custom(article, strategy=strategy)\n",
        "\n",
        "            rouge1 = compute_rouge_n(reference, generated, n=1)[\"f1\"]\n",
        "            rouge2 = compute_rouge_n(reference, generated, n=2)[\"f1\"]\n",
        "            rougel = compute_rouge_l(reference, generated)[\"f1\"]\n",
        "\n",
        "            results[strategy].append({\n",
        "                \"rouge1\": rouge1,\n",
        "                \"rouge2\": rouge2,\n",
        "                \"rougeL\": rougel\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[{strategy}] Error on sample {i}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ox7I3VxhzsbO",
      "metadata": {
        "id": "Ox7I3VxhzsbO"
      },
      "outputs": [],
      "source": [
        "summary = {}\n",
        "for strategy in strategies:\n",
        "    if results[strategy]:\n",
        "        rouge1s = [x[\"rouge1\"] for x in results[strategy]]\n",
        "        rouge2s = [x[\"rouge2\"] for x in results[strategy]]\n",
        "        rougels = [x[\"rougeL\"] for x in results[strategy]]\n",
        "\n",
        "        summary[strategy] = {\n",
        "            \"ROUGE-1\": np.mean(rouge1s),\n",
        "            \"ROUGE-2\": np.mean(rouge2s),\n",
        "            \"ROUGE-L\": np.mean(rougels)\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(summary).T.sort_values(\"ROUGE-L\", ascending=False)\n",
        "display(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc7f614",
      "metadata": {
        "id": "2fc7f614"
      },
      "source": [
        "## Discussion (Total: 15 points)\n",
        "Answer the following questions based on your decoding outputs and analysis. Be clear and support your claims with examples. You may provide your evidence by implementing additional functions. For example, you may draw a plot or show a statistics.\n",
        "\n",
        "1. Compare the different decoding strategies. Present and justify your findings using examples from your generated summaries. (9 points)\n",
        "  - Which strategies produce more diverse outputs?\n",
        "\n",
        "  - Which ones tend to repeat phrases or truncate early?\n",
        "\n",
        "  - Which are more stable across different runs?\n",
        "\n",
        "\n",
        "2. Analyze the impact of decoding parameters. Suggest complementary evaluation methods that might improve reliability. (3 points)\n",
        "  - How does increasing beam size or sampling temperature affect the results?\n",
        "\n",
        "  - Use at least one example to illustrate the effect.\n",
        "\n",
        "3. Discuss the limitations of ROUGE as an evaluation metric. Suggest complementary evaluation methods that might improve reliability. (3 points)\n",
        "  - What aspects of summarization quality does ROUGE fail to capture?\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deepseek_ft",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "749a0522c1c34568b4778ee9b4d5e925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3699e1cd564a460aa5798203bf0dbf4c",
              "IPY_MODEL_b98cbc3fa01a41a2bef3882f38282908",
              "IPY_MODEL_43ace8dbb2634c238d9e2836f81862fb"
            ],
            "layout": "IPY_MODEL_d83cac04ca7f4f2eac6c8df34aa6438d"
          }
        },
        "3699e1cd564a460aa5798203bf0dbf4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ea58bd63fb4f77a28fb5f714250216",
            "placeholder": "​",
            "style": "IPY_MODEL_cd057e63c14647c18def63fc21ac20a5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b98cbc3fa01a41a2bef3882f38282908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64b0aaa63674237b4b658738e5b6e40",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af4fd2fa135642bf9788f200cb4f2044",
            "value": 26
          }
        },
        "43ace8dbb2634c238d9e2836f81862fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fffce4414ed4edb93b46f41313400af",
            "placeholder": "​",
            "style": "IPY_MODEL_111ccf9331af43fdbfa555a44f8b5966",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.61kB/s]"
          }
        },
        "d83cac04ca7f4f2eac6c8df34aa6438d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ea58bd63fb4f77a28fb5f714250216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd057e63c14647c18def63fc21ac20a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c64b0aaa63674237b4b658738e5b6e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4fd2fa135642bf9788f200cb4f2044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fffce4414ed4edb93b46f41313400af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111ccf9331af43fdbfa555a44f8b5966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1c438c833c7425eb794e841536cc8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3d4c97f581a408bbbea1980a30af7e2",
              "IPY_MODEL_d4cc3bb1348647c9abfceaa6daefe402",
              "IPY_MODEL_cde08c3584a94499949bc6ef384555ab"
            ],
            "layout": "IPY_MODEL_70007bda0210464083f13bae67d0257e"
          }
        },
        "f3d4c97f581a408bbbea1980a30af7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25c5b5c7ee104737bdcdb493edb3a115",
            "placeholder": "​",
            "style": "IPY_MODEL_792c5b72236c45fd9eec5524c15c1887",
            "value": "config.json: 100%"
          }
        },
        "d4cc3bb1348647c9abfceaa6daefe402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c6119f525a4173bbb5533ce21bf9ec",
            "max": 1802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e8bff68f97c4228b87de21cd5c59d28",
            "value": 1802
          }
        },
        "cde08c3584a94499949bc6ef384555ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ac1ef272a947b4a6bc353db894d443",
            "placeholder": "​",
            "style": "IPY_MODEL_c1f7c88ae0964244b2da491ca05ba1b6",
            "value": " 1.80k/1.80k [00:00&lt;00:00, 201kB/s]"
          }
        },
        "70007bda0210464083f13bae67d0257e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c5b5c7ee104737bdcdb493edb3a115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792c5b72236c45fd9eec5524c15c1887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c6119f525a4173bbb5533ce21bf9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8bff68f97c4228b87de21cd5c59d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13ac1ef272a947b4a6bc353db894d443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f7c88ae0964244b2da491ca05ba1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc612ae5248e420eb101dfae477c1a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0dec88f3d4040d59b7dce138f5f9fb1",
              "IPY_MODEL_993a35aaac574fc6863a54524b391021",
              "IPY_MODEL_e550b62690f5493191cc805c56792afb"
            ],
            "layout": "IPY_MODEL_4b5a99e5c72d446a9e44a08a2c59b675"
          }
        },
        "d0dec88f3d4040d59b7dce138f5f9fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d5651ea0ff4e01acd6e0d67baec6fd",
            "placeholder": "​",
            "style": "IPY_MODEL_efeba7acaf2640ee8941c6e448d136db",
            "value": "vocab.json: 100%"
          }
        },
        "993a35aaac574fc6863a54524b391021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd76ef8911f48c3bb4e794b42f50582",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_805f5ca2afb54b2aa76d76e27ec2a851",
            "value": 898822
          }
        },
        "e550b62690f5493191cc805c56792afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_723a09f57c0f4284a69a2bf00dfc09c1",
            "placeholder": "​",
            "style": "IPY_MODEL_8f2da236c7ca4c4298a89f3bde86487a",
            "value": " 899k/899k [00:00&lt;00:00, 9.55MB/s]"
          }
        },
        "4b5a99e5c72d446a9e44a08a2c59b675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d5651ea0ff4e01acd6e0d67baec6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efeba7acaf2640ee8941c6e448d136db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd76ef8911f48c3bb4e794b42f50582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805f5ca2afb54b2aa76d76e27ec2a851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "723a09f57c0f4284a69a2bf00dfc09c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2da236c7ca4c4298a89f3bde86487a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2563dda79564d08a9fa9f7a1029cfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9eb8c5f6da52484387994a30dfa5fb71",
              "IPY_MODEL_fa50a74c62794b07bc4c818817aad479",
              "IPY_MODEL_a9569443d155484fbaa63d767e1aef12"
            ],
            "layout": "IPY_MODEL_46da4dea9b32451c99a3c942e419b400"
          }
        },
        "9eb8c5f6da52484387994a30dfa5fb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d804173162b4468ebe7f3a6dd4e9ec7b",
            "placeholder": "​",
            "style": "IPY_MODEL_59afbb47d7b24f5f9db20dfcf83540cf",
            "value": "merges.txt: 100%"
          }
        },
        "fa50a74c62794b07bc4c818817aad479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e30752ab6fe4f29a3953244574be804",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0871a0275134a40b0dbabc78bce7cbe",
            "value": 456318
          }
        },
        "a9569443d155484fbaa63d767e1aef12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0e5b0584f745c6b132998d282afa70",
            "placeholder": "​",
            "style": "IPY_MODEL_ed6ba303ca4544d98252dbf8270709ee",
            "value": " 456k/456k [00:00&lt;00:00, 3.16MB/s]"
          }
        },
        "46da4dea9b32451c99a3c942e419b400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d804173162b4468ebe7f3a6dd4e9ec7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59afbb47d7b24f5f9db20dfcf83540cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e30752ab6fe4f29a3953244574be804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0871a0275134a40b0dbabc78bce7cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d0e5b0584f745c6b132998d282afa70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed6ba303ca4544d98252dbf8270709ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6313a4351314a0ca290ffb185cd5150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a32ddd204f4e4cc394863ea3db2028a3",
              "IPY_MODEL_44bf1ac378ee4e72b84a9e11c6d786b9",
              "IPY_MODEL_6fc8b88fde304e17b094bbbf293c7d37"
            ],
            "layout": "IPY_MODEL_724963811439426b9dda30511a622a48"
          }
        },
        "a32ddd204f4e4cc394863ea3db2028a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21c5516c496f434da02348602199d5f6",
            "placeholder": "​",
            "style": "IPY_MODEL_062033d7c99c4418b41d91aac370bc6e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "44bf1ac378ee4e72b84a9e11c6d786b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_139c982e3b194c9dba36504eb3db951b",
            "max": 1222317369,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e876de1284a54e83a15d99aa5137ab85",
            "value": 1222317369
          }
        },
        "6fc8b88fde304e17b094bbbf293c7d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_114732ed2c064e4a8ea3dcc8bc44355c",
            "placeholder": "​",
            "style": "IPY_MODEL_70103858f17a424789683d4a1238e170",
            "value": " 1.22G/1.22G [00:05&lt;00:00, 255MB/s]"
          }
        },
        "724963811439426b9dda30511a622a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c5516c496f434da02348602199d5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "062033d7c99c4418b41d91aac370bc6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "139c982e3b194c9dba36504eb3db951b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e876de1284a54e83a15d99aa5137ab85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "114732ed2c064e4a8ea3dcc8bc44355c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70103858f17a424789683d4a1238e170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecef1ac1e57f4188b9c91d2f7a2c4d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3812d1f7b27e4dfc87f0283aba0ea5b0",
              "IPY_MODEL_bc5fed263ec64fb7a6aed3195e9e9cfa",
              "IPY_MODEL_ec5b9ea0374f48e2b5e1f2689a735f67"
            ],
            "layout": "IPY_MODEL_58a5f12854b24ec382ff4d998fe21974"
          }
        },
        "3812d1f7b27e4dfc87f0283aba0ea5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a7f6782e8541ec8a19a4b76f88d34c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a8cc7eb126b473aac197a969e51576e",
            "value": "model.safetensors: 100%"
          }
        },
        "bc5fed263ec64fb7a6aed3195e9e9cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fb393e638c444d99fe4cdfa8323e7af",
            "max": 1222284424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da20b564781547d896dfe47bafbadc65",
            "value": 1222284424
          }
        },
        "ec5b9ea0374f48e2b5e1f2689a735f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15ee039d17d4f06ad47f07ae1efea37",
            "placeholder": "​",
            "style": "IPY_MODEL_68bbf87091944903b882798cea4bd3e3",
            "value": " 1.22G/1.22G [00:05&lt;00:00, 245MB/s]"
          }
        },
        "58a5f12854b24ec382ff4d998fe21974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59a7f6782e8541ec8a19a4b76f88d34c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a8cc7eb126b473aac197a969e51576e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fb393e638c444d99fe4cdfa8323e7af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da20b564781547d896dfe47bafbadc65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c15ee039d17d4f06ad47f07ae1efea37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68bbf87091944903b882798cea4bd3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}