{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e53bf5c7",
      "metadata": {
        "id": "e53bf5c7"
      },
      "source": [
        "# Assignment 2: Implementing Decoding Strategies for Summarization (40 points)\n",
        "\n",
        "In this assignment, you will **implement decoding algorithms** used for text summarization using a pretrained Transformer model.\n",
        "\n",
        "---\n",
        "\n",
        "### Your Task\n",
        "1. **Load** the `sshleifer/distilbart-cnn-12-6` summarization model.\n",
        "2. **Implement the following decoding strategies from scratch** (no `.generate()` allowed!). You need to provide your own explanation on your implementation for each function:\n",
        "   - Greedy decoding (3 points)\n",
        "   - Top-k sampling (3 points)\n",
        "   - Top-p (nucleus) sampling (3 points)\n",
        "   - Beam search (3 points)\n",
        "   - Beam search with n-gram blocking (3 points)\n",
        "3. Use your decoder to summarize 200 articles from the CNN/DailyMail dataset.\n",
        "4. Implement the following ROUGE metrics and evaluate your summaries using your own ROUGE metric implementation.\n",
        "  - Implementation\n",
        "    - ROUGE-n (2 points): e.g., ROUGE-1 & ROUGE-2\n",
        "    - ROUGE-L (4 points)\n",
        "  - Explanation on your implementation (2 points)\n",
        "  - Discuss how to improve these metrics to perform a better evaluation? (2 points)\n",
        "5. Discussion (15 points)\n",
        "\n",
        "---\n",
        "\n",
        "**Note:**\n",
        "  - Regarding the decoding strategies, you are expected to work directly with model logits and sampling logic. Do not use `model.generate()` or any pre-built function. **Hint**: use \"outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\"\n",
        "  - For each function, you need to write clear and concise comments about your implementation. This may not be line-by-line, but rather meaningful chunk of codes.\n",
        "  - For each question, justify your answer with explanations.\n",
        "\n",
        "### **We highly recommend using 'cpu' as the default for development, and switching to 'gpu' only for evaluating summarization performance. This is due to the limited GPU availability in the Colab environment.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f3b788c8",
      "metadata": {
        "id": "f3b788c8"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f2b0b6c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2b0b6c5",
        "outputId": "073cb56f-6596-472b-e5b1-9a798d0eb271"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data2/cmdir/home/giangnl/.conda/envs/deepseek_ft/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "# load model to gpu for faster inference\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71208984",
      "metadata": {
        "id": "71208984"
      },
      "source": [
        "In this assignment, we use the CNN/DailyMail summarization dataset, a widely-used benchmark for training and evaluating text summarization models.\n",
        "\n",
        "Each data sample consists of:\n",
        "\n",
        "- article: A news story, usually between 300 and 800 words.\n",
        "\n",
        "- highlights: A bullet-style abstractive summary of the article, written by human editors.\n",
        "\n",
        "This dataset is ideal for testing decoding strategies because:\n",
        "\n",
        "- The summaries are relatively short and factual\n",
        "\n",
        "- The dataset is large enough to support diverse decoding behavior\n",
        "\n",
        "- It has been used in many summarization papers, making ROUGE scores easy to compare\n",
        "\n",
        "In this assignment, we will use a small subset of 200 samples from the validation set for quick experimentation and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a1d2d74e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "a1d2d74e",
        "outputId": "b4134236-8eaa-4041-be0b-e8d2c8f5e220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Because the limited computation resource in google collab, I only use first 10 samples from the dataset to run experiment.\n",
            "Loaded 10 samples.\n",
            "\n",
            "Example article:\n",
            "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday's ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court's treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What's objectionable is the attempts to undermine international justice, not Palestine's decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court's decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN's Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.\n",
            "\n",
            "Reference summary:\n",
            "Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n"
          ]
        }
      ],
      "source": [
        "# Upload cnn_dm_200.json file\n",
        "\n",
        "# Load 200-sample dataset\n",
        "with open(\"cnn_dm_200.json\", \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "print(\"Because the limited computation resource in google collab, I only use first 10 samples from the dataset to run experiment.\")\n",
        "dataset = dataset[:10]\n",
        "\n",
        "print(f\"Loaded {len(dataset)} samples.\")\n",
        "print(\"\\nExample article:\")\n",
        "print(dataset[0][\"article\"])\n",
        "print(\"\\nReference summary:\")\n",
        "print(dataset[0][\"highlights\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491ce644",
      "metadata": {
        "id": "491ce644"
      },
      "source": [
        "## Decoding in Language Models\n",
        "Pretrained language models like BART or GPT generate text by predicting the most likely next token one at a time.\n",
        "However, simply choosing the most probable token at each step often leads to deterministic, repetitive, or generic outputs.\n",
        "\n",
        "To overcome this, several decoding strategies have been proposed to balance:\n",
        "\n",
        "- fluency vs. diversity\n",
        "\n",
        "- coherence vs. novelty\n",
        "\n",
        "In this assignment, you will implement five widely-used decoding strategies from scratch and compare their effects."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75e0c151",
      "metadata": {
        "id": "75e0c151"
      },
      "source": [
        "### Greedy Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "42d72411",
      "metadata": {
        "id": "42d72411"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(input_ids, max_length=30):\n",
        "    \"\"\"\n",
        "    Perform greedy decoding from the model using logits.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Greedy Decoding from scratch\n",
        "    input_ids = input_ids.to(device) # load model to device\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "\n",
        "    for _ in range(max_length):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "        proba_output = torch.softmax(output.logits[:,-1,:],axis=-1) # take the last token logits and apply softmax to get the probability of each token\n",
        "        id = torch.tensor([[torch.argmax(proba_output, axis=-1)]]).to(device) # greedy approach to take the token_id with largest probability\n",
        "        decoder_input_ids = torch.cat([decoder_input_ids,id],axis=-1) # append the decoded token to the generated token sequence\n",
        "\n",
        "        if id.item() == eos_token_id: # If the model generate an EOS token, the decoding process should be stop\n",
        "            break\n",
        "\n",
        "    summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True) # convert the generated token sequence to string\n",
        "\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AW2YSwP3PGcn",
      "metadata": {
        "id": "AW2YSwP3PGcn"
      },
      "source": [
        "Explain your implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0b256c",
      "metadata": {
        "id": "ed0b256c"
      },
      "source": [
        "My implementation performs greedy decoding for a sequence-to-sequence model by iteratively generating tokens based on the highest probability prediction at each step. Firstly, it inputs a decoder start token id to start auto-regressive process. The model takes in decoder start token id and returns logits for next token. The softmax function is applied to convert logits to probabilites, and the token id, which is the index in the tensor, is chosen with respect to the highest probability. The chosen token id is then concatenated with the sequence of previously generated tokens, to feed back into the model for the next iteration. The process stop until model outputs the end of sentence token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba10a34",
      "metadata": {
        "id": "dba10a34"
      },
      "source": [
        "### Top-k Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "22a1957b",
      "metadata": {
        "id": "22a1957b"
      },
      "outputs": [],
      "source": [
        "def top_k_decode(input_ids, k=5, max_length=30, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Perform Top-k sampling decoding from the model.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        k (int): Number of top tokens to sample from.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "        temperature (float): Softmax temperature for sampling.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Top-k Sampling Decoding\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      with torch.no_grad():\n",
        "        output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "      output_proba = torch.softmax(output.logits[:,-1,:]/temperature,axis=-1) # convert logits to probability, devide by the temperature to control the randomness and shape of probability distribution\n",
        "      values, indices = torch.topk(output_proba, k=k, axis=-1) # take top k tokens with largest probability\n",
        "      values = values/ torch.sum(values,axis=-1,keepdim=True).item() # redistribute probability of selected tokens, made them summing up to 1\n",
        "      local_index = torch.multinomial(values[0],num_samples=1) # sampling from redistributed probability distribution\n",
        "      id = indices[:,local_index] # take the token id of the sampled token\n",
        "      decoder_input_ids = torch.cat([decoder_input_ids,id],axis=-1) # add the sampled token to the generated token sequence\n",
        "\n",
        "      if id.item() == eos_token_id: # If the model generate an EOS token, the decoding process should be stop\n",
        "        break\n",
        "\n",
        "    summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True) # convert the generated token sequence to string\n",
        "    return summary\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oyFRQsTiPWHn",
      "metadata": {
        "id": "oyFRQsTiPWHn"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa8530e",
      "metadata": {
        "id": "0aa8530e"
      },
      "source": [
        "- My implementation of top-k sampling involves selecting the top k most probable tokens from the model's output logits at each decoding step. The logits are first converted to probabilities using the softmax function. Then, use torch.topk function to select k indices with largest probabilities. Then, the probabilities of k selected tokens must be redistributed to have sum of 1. After that, I sample a token using torch.multinomial function to sample elements from a given probability distribution. This process is repeated until an end-of-sequence token is generated or a maximum length is reached.\n",
        "- The hyperparameter k determines the number of top tokens to consider for sampling. A smaller k leads to more deterministic outputs, as fewer options are available, while a larger k increases diversity but may introduce noise. If k is set too high, the model may generate less coherent or relevant text, as it has too many options to choose from. Conversely, if k is too low, the generated text may become repetitive or lack variety. If k is set to 1, top k sampling becomes equivalent to greedy decoding, as only the most probable token is selected at each step.\n",
        "- The hyperpatameter temperature is used to control the randomness of the sampling process. A lower temperature results in more conservative and deterministic outputs, while a higher temperature increases diversity but may lead to less coherent text. If the temperature is set to 1, it means no scaling is applied to the logits, and the sampling process behaves as if it were using the original probabilities. If we increase the temperature, the probabilities distribution becomes more uniform. In contrast, we reduce the temperature, the distribution becomes sharper."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06aad60",
      "metadata": {
        "id": "b06aad60"
      },
      "source": [
        "### Top-p Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe9c4772",
      "metadata": {
        "id": "fe9c4772"
      },
      "outputs": [],
      "source": [
        "def top_p_decode(input_ids, p=0.9, max_length=30, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Perform Top-p (nucleus) sampling decoding from the model.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        p (float): Cumulative probability threshold for sampling.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "        temperature (float): Softmax temperature for sampling.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Top-p Sampling Decoding\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      with torch.no_grad():\n",
        "        output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "      output_proba = torch.softmax(output.logits[:,-1,:]/temperature,axis=-1)[0] # convert logits to probability, devide by the temperature to control the randomness and shape of probability distribution\n",
        "      sorted_probs, sorted_indices = torch.sort(output_proba, descending=True) # sort the probabilites and their corresponding token ids\n",
        "      cumulative_probs = torch.cumsum(sorted_probs, dim=0) # calculate the cumulative probability\n",
        "      nucleus_mask = cumulative_probs <= p # create a mask for the tokens that are below the threshold\n",
        "      nucleus_mask[max((cumulative_probs > p).nonzero(as_tuple=True)[0][0], 0)] = True # Ensure we include at least one token after passing threshold\n",
        "      nucleus_probs = sorted_probs[nucleus_mask] # filter the probabilities based on the mask\n",
        "      nucleus_indices = sorted_indices[nucleus_mask] # filter the token ids based on the mask\n",
        "      nucleus_probs = nucleus_probs/torch.sum(nucleus_probs) # redistribute the probabilities of the selected tokens\n",
        "      local_index = torch.multinomial(nucleus_probs,num_samples=1) # sampling from redistributed probability distribution\n",
        "      id = torch.tensor([[nucleus_indices[local_index]]]).to(device)\n",
        "      decoder_input_ids = torch.cat([decoder_input_ids,id],axis=-1)\n",
        "\n",
        "      if id.item() == eos_token_id: # If the model generate an EOS token, the decoding process should be stop\n",
        "        break\n",
        "\n",
        "\n",
        "    summary = tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ynhylQrWPXJi",
      "metadata": {
        "id": "ynhylQrWPXJi"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081cae83",
      "metadata": {
        "id": "081cae83"
      },
      "source": [
        "- My implementation of top-p (percentile) decoding is different from top-k sampling in that: It selects the smallest set of tokens whose cumulative probability exceeds a threshold p. The logits are first devided by temperature to control the shape of distribution and converted to probabilities using the softmax function. Then, I sort the probabilities in descending order and compute the cumulative sum. I select the smallest set of tokens such that their cumulative probability is greater than or equal to p, implemented by using masks for filtering in tensor. After that, the probabilities of selected candidates must be redistributed to sum up 1. Afterwards, I sample a token from this set and the remaining process is similar to the top-k sampling method. This process is repeated until an end-of-sequence token is generated or a maximum length is reached.      \n",
        "- The hyperparameter p determines the threshold for cumulative probability. A smaller p leads to more deterministic outputs, as fewer options are available, while a larger p increases diversity but may introduce noise. If p is set too high, the model may generate less coherent or relevant text, as it has too many options to choose from. Conversely, if p is too low, the generated text may become repetitive or lack variety.\n",
        "- The hyperpatameter temperature is used to control the randomness of the sampling process. A lower temperature results in more conservative and deterministic outputs, while a higher temperature increases diversity but may lead to less coherent text. If the temperature is set to 1, it means no scaling is applied to the logits, and the sampling process behaves as if it were using the original probabilities. If we increase the temperature, the probabilities distribution becomes more uniform. In contrast, we reduce the temperature, the distribution becomes sharper.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b274b9f",
      "metadata": {
        "id": "2b274b9f"
      },
      "source": [
        "### Beam Search Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9fa0a79",
      "metadata": {
        "id": "f9fa0a79"
      },
      "outputs": [],
      "source": [
        "def beam_search_decode(input_ids, beam_size=2, max_length=30):\n",
        "    \"\"\"\n",
        "    Perform beam search decoding from the model.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        beam_size (int): Number of beams to explore.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Beam Search Decoding\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device) # take the start token for decoding\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "    vocab_size = model.config.vocab_size # take the vocab size from the model config\n",
        "\n",
        "    top_beam = [] # to store top k beams with highest probability at each step\n",
        "    with torch.no_grad():\n",
        "      output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
        "\n",
        "    output_proba = torch.softmax(output.logits[:,-1,:],axis=-1)\n",
        "    probas, indices = torch.topk(output_proba,k=beam_size,axis=-1) # select top k tokens with largest probability, called beams in the first step\n",
        "    for index,proba in zip(indices[0],probas[0]):\n",
        "      top_beam.append((torch.tensor([[decoder_input_ids,index]]),proba.item())) # append top k beams to the list to start the beam search process\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      beam_list = [] # beam list to store all the beams, total number of beams in comparison will be beam_size * vocab_size\n",
        "      for beam in top_beam:\n",
        "        with torch.no_grad():\n",
        "          output = model(input_ids=input_ids, decoder_input_ids=beam[0].to(device)).logits[:,-1,:]\n",
        "        output_proba = beam[1] * torch.softmax(output,axis=-1) # calculate the cumulative probability by multiplying the probability of the current beam with the conditional probability of the next token\n",
        "        for idx,local_proba in enumerate(list(output_proba[0])):\n",
        "          beam_list.append((torch.cat([beam[0],torch.tensor([[idx]])],axis=-1), local_proba.item())) # append each candidate to the beam list, the candidate is the current beam with the next token id appended to it\n",
        "\n",
        "      sorted_beam_list = sorted(beam_list, key=lambda item: item[1], reverse=True) # sort the beam list based on the cumulated probability for later selection\n",
        "      top_beam = sorted_beam_list[:beam_size] # select top k beams with largest probability\n",
        "\n",
        "      if top_beam[0][0][0][-1].item() == eos_token_id:\n",
        "        break\n",
        "\n",
        "    summary = tokenizer.decode(top_beam[0][0][0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H36U-rVaPYBQ",
      "metadata": {
        "id": "H36U-rVaPYBQ"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc8d94b",
      "metadata": {
        "id": "bdc8d94b"
      },
      "source": [
        "- My implementation of beam search decoding involves maintaining a fixed number of candidate sequences (beams) at each decoding step. The process starts with the decoder start token id and iteratively expands each beam by generating the next token probabilities. For each beam, I compute the probabilities of all possible next tokens and select the top k beams based on their cumulative probabilities. This is done using append all possible beams to the list and sorted based on their probabilities. The process continues until an end-of-sequence token is generated and is selected as the highest probable beam or a maximum length is reached.\n",
        "- The hyperparameter k (beam width) determines the number of candidate sequences to maintain at each step. A larger k increases the search space and may result in more diverse output as it can explore beam with higher probability. This may leads to more coherent outputs, but also increases computational cost. A smaller k reduces the search space and may lead to less diverse outputs. If k is set to 1, beam search becomes equivalent to greedy decoding, as only the most probable sequence is selected at each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72276cb9",
      "metadata": {
        "id": "72276cb9"
      },
      "source": [
        "### Beam Search with N-gram Blocking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cacdfda9",
      "metadata": {
        "id": "cacdfda9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def isBlocked(token_seq: list(), no_repeat_ngram_size: int, next_token: int):\n",
        "  '''\n",
        "  This function checks if the next token is blocked by the n-gram repetition blocking rule.\n",
        "  It iteratively check if the next token is in the last n-gram size of the token sequence.\n",
        "  '''\n",
        "  if len(token_seq) < no_repeat_ngram_size:\n",
        "    return False\n",
        "  candidate_seq = token_seq[-(no_repeat_ngram_size-1):] + [next_token]\n",
        "\n",
        "  for i in range(len(token_seq)-(no_repeat_ngram_size-1)):\n",
        "    ref_seq = token_seq[i: i+ no_repeat_ngram_size]\n",
        "    if ref_seq == candidate_seq:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def beam_search_ngram_block(input_ids, beam_size=2, max_length=30, no_repeat_ngram_size=3):\n",
        "    \"\"\"\n",
        "    Perform beam search decoding with n-gram repetition blocking.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tokenized input tensor of shape [1, seq_len].\n",
        "        beam_size (int): Number of beams to explore.\n",
        "        max_length (int): Maximum length of the generated sequence.\n",
        "        no_repeat_ngram_size (int): Size of n-gram to prevent from repeating.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded summary text.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Beam Search with n-gram blocking\n",
        "\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]]).to(device)\n",
        "    eos_token_id = model.config.eos_token_id # take the EOS token id from the vocab\n",
        "    vocab_size = model.config.vocab_size # take the vocab size from the model config\n",
        "\n",
        "    top_beam = []\n",
        "    with torch.no_grad():\n",
        "      output = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids).logits[:,-1,:]\n",
        "    output_proba = torch.softmax(output,axis=-1)\n",
        "    probas, indices = torch.topk(output_proba,k=beam_size,axis=-1)\n",
        "    for index,proba in zip(indices[0],probas[0]):\n",
        "      top_beam.append((torch.tensor([[decoder_input_ids,index]]),proba.item()))\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      beam_list = []\n",
        "      for beam in top_beam:\n",
        "        with torch.no_grad():\n",
        "          output = model(input_ids=input_ids, decoder_input_ids=beam[0].to(device))\n",
        "        output = output.logits[:,-1,:]\n",
        "        output_proba = beam[1] * torch.softmax(output,axis=-1)\n",
        "        for idx,local_proba in enumerate(list(output_proba[0])):\n",
        "          if not isBlocked(token_seq=beam[0][0].tolist(),no_repeat_ngram_size=no_repeat_ngram_size,next_token=idx): # check if the next token is blocked by the n-gram repetition blocking rule before being added to the beam list\n",
        "            beam_list.append((torch.cat([beam[0],torch.tensor([[idx]])],axis=-1), local_proba.item()))\n",
        "      sorted_beam_list = sorted(beam_list, key=lambda item: item[1], reverse=True)\n",
        "      top_beam = sorted_beam_list[:beam_size]\n",
        "\n",
        "      if top_beam[0][0][0][-1].item() == eos_token_id:\n",
        "        break\n",
        "\n",
        "    summary = tokenizer.decode(top_beam[0][0][0], skip_special_tokens=True)\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hBw-4rWiPZTm",
      "metadata": {
        "id": "hBw-4rWiPZTm"
      },
      "source": [
        "- Explain your implementation.\n",
        "- What are the role of hyperparameters of this strategy? and what happen if you change the values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88fcc4a",
      "metadata": {
        "id": "b88fcc4a"
      },
      "source": [
        "- My implementation for beam search with n-gram blocking is almost similar to the implementation of beam search decoding, except the checking of valid beams. before the candidate beam is added to the list, it should be checked if it creates n-grams that are already present in the previous beams. If it does, it is discarded.\n",
        "- The hyperparameter n (no_repeat_ngram_size) determines the size of the n-grams to block. A larger n leads to less aggressive blocking as only large n-grams are blocked, allowing short repetition. A smaller n avoids more repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e4cecd13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4cecd13",
        "outputId": "f547a954-7e60-4292-c6d3-291445eefedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greedy Search:\n",
            " The Palestinian Authority becomes the 123rd member of the International Criminal Court . The move gives the court jurisdiction over alleged crimes in Palestinian territories . Israel and the\n",
            "\n",
            "Top k decoding:\n",
            " The Palestinian Authority is officially the 123rd member of the Criminal Court . It has signed the Rome Statute and accepted its jurisdiction in the Palestinian territory .\n",
            "\n",
            "Top p decoding:\n",
            " ICC has jurisdiction over alleged crimes in Palestinian territories . The International Criminal Court was set up in 2002 .\n",
            "\n",
            "Beam search decoding:\n",
            " The Palestinian Authority becomes the 123rd member of the International Criminal Court . The move gives the court jurisdiction over alleged crimes in Palestinian territories . Israel and the United\n",
            "\n",
            "Beam Search + N-gram Blocking:\n",
            " The Palestinian Authority becomes the 123rd member of the International Criminal Court . The move gives the court jurisdiction over alleged crimes in Palestinian territories . Israel and the United\n",
            "Execution time (in seconds): 288.24523997306824\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# Example usage with the above decoding functions\n",
        "input_text = dataset[0]['article']\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"Greedy Search:\")\n",
        "print(greedy_decode(input_ids))\n",
        "\n",
        "print(\"\\nTop k decoding:\")\n",
        "print(top_k_decode(input_ids))\n",
        "\n",
        "print(\"\\nTop p decoding:\")\n",
        "print(top_p_decode(input_ids))\n",
        "\n",
        "print(\"\\nBeam search decoding:\")\n",
        "print(beam_search_decode(input_ids))\n",
        "\n",
        "print(\"\\nBeam Search + N-gram Blocking:\")\n",
        "print(beam_search_ngram_block(input_ids))\n",
        "\n",
        "end_time = time.time()\n",
        "excecution_time = end_time - start_time\n",
        "print(f\"Execution time (in seconds): {excecution_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fe1341",
      "metadata": {
        "id": "25fe1341"
      },
      "source": [
        "## ROUGE Metric Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4bacaa3b",
      "metadata": {
        "id": "4bacaa3b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def compute_rouge_n(reference: str, generated: str, n: int = 1) -> dict:\n",
        "    \"\"\"\n",
        "    Compute ROUGE-N score between reference and generated text.\n",
        "\n",
        "    Args:\n",
        "        reference (str): The reference summary.\n",
        "        generated (str): The generated summary.\n",
        "        n (int): The n-gram size (e.g., 1 for ROUGE-1).\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with 'precision', 'recall', and 'f1' scores.\n",
        "    \"\"\"\n",
        "    ref_tokens = tokenize(reference)\n",
        "    gen_tokens = tokenize(generated)\n",
        "\n",
        "    ref_ngrams = Counter([tuple(ref_tokens[i:i+n]) for i in range(len(ref_tokens)-n+1)])\n",
        "    gen_ngrams = Counter([tuple(gen_tokens[i:i+n]) for i in range(len(gen_tokens)-n+1)])\n",
        "\n",
        "\n",
        "    overlap = sum((ref_ngrams & gen_ngrams).values())\n",
        "\n",
        "    precision = overlap / sum(gen_ngrams.values()) if gen_ngrams else 0.0\n",
        "    recall = overlap / sum(ref_ngrams.values()) if ref_ngrams else 0.0\n",
        "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "def lcs(X, Y):\n",
        "    \"\"\"\n",
        "    Helper function to compute the length of Longest Common Subsequence (LCS)\n",
        "    \"\"\"\n",
        "    m, n = len(X), len(Y)\n",
        "    dp = [[0] * (n+1) for _ in range(m+1)]\n",
        "\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            if X[i] == Y[j]:\n",
        "                dp[i+1][j+1] = dp[i][j] + 1\n",
        "            else:\n",
        "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
        "    return dp[m][n]\n",
        "\n",
        "def compute_rouge_l(reference: str, generated: str) -> dict:\n",
        "    \"\"\"\n",
        "    Compute ROUGE-L (Longest Common Subsequence) score.\n",
        "\n",
        "    Args:\n",
        "        reference (str): The ground truth summary.\n",
        "        generated (str): The generated summary by the model.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with precision, recall, and f1 scores.\n",
        "    \"\"\"\n",
        "    ref_tokens = tokenize(reference)\n",
        "    gen_tokens = tokenize(generated)\n",
        "\n",
        "    lcs_len = lcs(ref_tokens, gen_tokens)\n",
        "\n",
        "    precision = lcs_len / len(gen_tokens) if gen_tokens else 0.0\n",
        "    recall = lcs_len / len(ref_tokens) if ref_tokens else 0.0\n",
        "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WRupJH9OPdqJ",
      "metadata": {
        "id": "WRupJH9OPdqJ"
      },
      "source": [
        "- Explanation on your implementation\n",
        "- Discuss how to improve these metrics to perform a better evaluation?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8acfcb1b",
      "metadata": {},
      "source": [
        "- My implementation of ROUGE metrics involves computing the overlap between the generated summary and the reference summary. I implemented ROUGE-1, ROUGE-2, and ROUGE-L metrics. For ROUGE-1 and ROUGE-2, I compute the precision, recall, and F1 score based on unigrams and bigrams respectively. For ROUGE-L, I compute the longest common subsequence (LCS) using dynamic programming method, the LCS is computed from the tokenizations by words of generated and reference summaries. The precision, recall, and F1 scores are calculated based on the LCS length.\n",
        "- To improve the evaluation of ROUGE metrics, we can consider the following approaches:\n",
        "  - Use more sophisticated tokenization methods that better capture the semantics of the text.\n",
        "  - Incorporate semantic similarity measures, such as BERTScore or BLEURT, which consider the meaning of words and phrases rather than just surface-level matches.\n",
        "  - We can evaluate the semantic meaning by using a pretrained language models and compare the representations of reference and generated texts returned by the LM. We can use cosine similarity of mean square error to measure the similarity of two texts.  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "105bd846",
      "metadata": {
        "id": "105bd846"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6f2f8f57",
      "metadata": {
        "id": "6f2f8f57"
      },
      "outputs": [],
      "source": [
        "def generate_summary_custom(article_text, strategy=\"greedy\", max_length=30, temperature=1.0, k=5, p=0.9, beam_size=2, no_repeat_ngram_size=3):\n",
        "    input_ids = tokenizer(article_text, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
        "    if strategy == \"greedy\":\n",
        "        return greedy_decode(input_ids,max_length=max_length)\n",
        "    elif strategy == \"top_k\":\n",
        "        return top_k_decode(input_ids, k=k, max_length=max_length, temperature=temperature)\n",
        "    elif strategy == \"top_p\":\n",
        "        return top_p_decode(input_ids, p=p, max_length=max_length, temperature=temperature)\n",
        "    elif strategy == \"beam\":\n",
        "        return beam_search_decode(input_ids, beam_size=beam_size, max_length=max_length)\n",
        "    elif strategy == \"beam_block\":\n",
        "        return beam_search_ngram_block(input_ids,beam_size=beam_size, max_length=max_length, no_repeat_ngram_size=no_repeat_ngram_size)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown decoding strategy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "fbbb0f60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbbb0f60",
        "outputId": "271a1f7f-ceee-4aa4-b4cd-390d7bf27553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[GREEDY]\n",
            " The Palestinian Authority becomes the 123rd member of the International Criminal Court . The move gives the court jurisdiction over alleged crimes in Palestinian territories . Israel and the\n",
            "\n",
            "[TOP_K]\n",
            " The Palestinian Authority formally joins the ICC in a ceremony in the Hague . It gives the court jurisdiction over alleged crimes in Palestinian territories . Palestinians signed the Rome\n",
            "\n",
            "[TOP_P]\n",
            " Palestinian Authority formally becomes 123rd member of the International Criminal Court . The move means the court can investigate alleged crimes committed by Palestinians in Palestinian territories . Israel\n",
            "\n",
            "[BEAM]\n",
            " The Palestinian Authority becomes the 123rd member of the International Criminal Court . The move gives the court jurisdiction over alleged crimes in Palestinian territories . Israel and the United\n",
            "\n",
            "[BEAM_BLOCK]\n",
            " The Palestinian Authority becomes the 123rd member of the International Criminal Court . The move gives the court jurisdiction over alleged crimes in Palestinian territories . Israel and the United\n"
          ]
        }
      ],
      "source": [
        "# Compare summaries across all decoding strategies for one article\n",
        "sample_article = dataset[0][\"article\"]\n",
        "for strategy in [\"greedy\", \"top_k\", \"top_p\", \"beam\", \"beam_block\"]:\n",
        "    print(f\"\\n[{strategy.upper()}]\")\n",
        "    print(generate_summary_custom(sample_article, strategy=strategy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "RK_9phseyjdx",
      "metadata": {
        "id": "RK_9phseyjdx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Decoding strategies\n",
        "strategies = [\"greedy\", \"top_k\", \"top_p\", \"beam\", \"beam_block\"]\n",
        "\n",
        "# Save evalution results\n",
        "results = {s: [] for s in strategies}\n",
        "\n",
        "# Evaluation loop\n",
        "for i, sample in enumerate(dataset):\n",
        "    article = sample[\"article\"]\n",
        "    reference = sample[\"highlights\"]\n",
        "\n",
        "    input_ids = tokenizer(article, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
        "\n",
        "    for strategy in strategies:\n",
        "        try:\n",
        "            generated = generate_summary_custom(article, strategy=strategy)\n",
        "\n",
        "            rouge1 = compute_rouge_n(reference, generated, n=1)[\"f1\"]\n",
        "            rouge2 = compute_rouge_n(reference, generated, n=2)[\"f1\"]\n",
        "            rougel = compute_rouge_l(reference, generated)[\"f1\"]\n",
        "\n",
        "            results[strategy].append({\n",
        "                \"rouge1\": rouge1,\n",
        "                \"rouge2\": rouge2,\n",
        "                \"rougeL\": rougel\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[{strategy}] Error on sample {i}: {e}\")\n",
        "\n",
        "# code to save results\n",
        "with open(\"evaluation_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "Ox7I3VxhzsbO",
      "metadata": {
        "id": "Ox7I3VxhzsbO"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROUGE-1</th>\n",
              "      <th>ROUGE-2</th>\n",
              "      <th>ROUGE-L</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>beam_block</th>\n",
              "      <td>0.379377</td>\n",
              "      <td>0.173001</td>\n",
              "      <td>0.301944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beam</th>\n",
              "      <td>0.379377</td>\n",
              "      <td>0.173001</td>\n",
              "      <td>0.301944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>greedy</th>\n",
              "      <td>0.363385</td>\n",
              "      <td>0.171099</td>\n",
              "      <td>0.265483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_p</th>\n",
              "      <td>0.343439</td>\n",
              "      <td>0.114834</td>\n",
              "      <td>0.260231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top_k</th>\n",
              "      <td>0.302477</td>\n",
              "      <td>0.094162</td>\n",
              "      <td>0.210998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ROUGE-1   ROUGE-2   ROUGE-L\n",
              "beam_block  0.379377  0.173001  0.301944\n",
              "beam        0.379377  0.173001  0.301944\n",
              "greedy      0.363385  0.171099  0.265483\n",
              "top_p       0.343439  0.114834  0.260231\n",
              "top_k       0.302477  0.094162  0.210998"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Because the limited computation resource in google collab, I only use first 10 samples from the dataset to run experiment.\n",
            "This table result follows the following paramater settings: \n",
            " p = 0.9, k = 5, beam size = 2, n-gram size = 3, max_length = 30\n"
          ]
        }
      ],
      "source": [
        "strategies = [\"greedy\", \"top_k\", \"top_p\", \"beam\", \"beam_block\"]\n",
        "results = json.load(open(\"evaluation_results.json\", \"r\"))\n",
        "summary = {}\n",
        "for strategy in strategies:\n",
        "    if results[strategy]:\n",
        "        rouge1s = [x[\"rouge1\"] for x in results[strategy]]\n",
        "        rouge2s = [x[\"rouge2\"] for x in results[strategy]]\n",
        "        rougels = [x[\"rougeL\"] for x in results[strategy]]\n",
        "\n",
        "        summary[strategy] = {\n",
        "            \"ROUGE-1\": np.mean(rouge1s),\n",
        "            \"ROUGE-2\": np.mean(rouge2s),\n",
        "            \"ROUGE-L\": np.mean(rougels)\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(summary).T.sort_values(\"ROUGE-L\", ascending=False)\n",
        "df.to_csv(\"evaluation_summary.csv\")\n",
        "display(df)\n",
        "print(\"Because the limited computation resource in google collab, I only use first 10 samples from the dataset to run experiment.\")\n",
        "print(f\"This table result follows the following paramater settings: \\n p = 0.9, k = 5, beam size = 2, n-gram size = 3, max_length = 30\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc7f614",
      "metadata": {
        "id": "2fc7f614"
      },
      "source": [
        "## Discussion (Total: 15 points)\n",
        "Answer the following questions based on your decoding outputs and analysis. Be clear and support your claims with examples. You may provide your evidence by implementing additional functions. For example, you may draw a plot or show a statistics.\n",
        "\n",
        "1. Compare the different decoding strategies. Present and justify your findings using examples from your generated summaries. (9 points)\n",
        "  - Which strategies produce more diverse outputs?\n",
        "\n",
        "Among the strategies, top-k and top-p sampling produce more diverse outputs compared to greedy decoding and beam search. When I set parameter p and k to high enough value such as 90 percentile or top 30000 out of vocab size. The reason is that these sampling methods allow for a wider range of token choices at each step, leading to more varied summaries. \n",
        "\n",
        "  - Which ones tend to repeat phrases or truncate early?\n",
        "\n",
        "The greedy and beam search decoding methods tend to repeat phrases or truncate early. This is because they focus on the most probable tokens at each step, which can lead to repetitive patterns. The beam search with n-gram blocking can prevent the repetition.\n",
        "\n",
        "  - Which are more stable across different runs?\n",
        "\n",
        "\n",
        "Greedy decoding and beam search tend to produce more deterministic outputs, as they focus on the most probable tokens. The beam search method, even with n-gram blocking, still tends to generate similar outputs across different runs, which is similar to the output of greedy decoding. Even when I increased the beam size, the generated summaries were still similar accross different runs. When I printed out the cumulated probabilities, which is achieved by mutiplying the probabilities of each token in the beam, I figured out that the search for large beam size can not help the model to find another higher probability. The highest one always starts from the highest probable beam in the first step. This can be explained by multiplying many probabilities together overally mades the cumulated one become monotical decreasing. \n",
        "\n",
        "2. Analyze the impact of decoding parameters. Suggest complementary evaluation methods that might improve reliability. (3 points)\n",
        "  - How does increasing beam size or sampling temperature affect the results?\n",
        "  \n",
        "  - Use at least one example to illustrate the effect.\n",
        "\n",
        "To answer those questions, I will create 2 box plots, 1 for testing the effect of different beam sizes and the other for testing the effect of different sampling temperatures. I will use the mean value of ROUGE-1, ROUGE-2 and ROUGE-L as the evaluation metric, and plot them using box plots, collected from different samples in the dataset.\n",
        "\n",
        "\n",
        "![Compare different beam sizes](./beam_sizes_result.png)\n",
        "\n",
        "Based on the results stored in the table beam_sizes_results.csv, we can see that with large beam size (eg. 4), the model can search for more probable candidates, which may leads to higher scores. Clearly, in sample 3, while beam size 1,2 and 3 returned rouge score 0.05, beam size 4 returned a much larger score of 0.3.\n",
        "\n",
        "![Compare different temperatures](./temperatures_result.png)\n",
        "\n",
        "From the boxplots of top-k methods, we can see that the larger the temperature, the more diversity of the output that model can generate, which may leads to lower ROUGE scores. With large temperature, the model predicts more rare words, hence the output significantly diverges compared to the reference summary. We can witness the means of the boxplots gradually decrease as the temperature increases. Some samples have rouge score 0 because the temperature is too high, which create the uniform distribution and the model can not predict any word that is in the reference summary.\n",
        "\n",
        "3. Discuss the limitations of ROUGE as an evaluation metric. Suggest complementary evaluation methods that might improve reliability. (3 points)\n",
        "  - What aspects of summarization quality does ROUGE fail to capture?\n",
        "\n",
        "ROUGE fails to capture several aspects of summarization quality, including:\n",
        "- Semantic meaning: ROUGE primarily focuses on n-gram overlap, which may not accurately reflect the semantic similarity between the generated summary and the reference summary. It may miss important information or context that is not captured by surface-level matching.\n",
        "- Coherence and fluency: ROUGE does not evaluate the coherence or fluency of the generated summary. A summary may have high ROUGE scores but still be incoherent or poorly written.\n",
        "\n",
        "\n",
        "Other complementary evaluation methods that might improve reliability include:\n",
        "- Human evaluation: Involving human annotators to assess the quality of generated summaries based on criteria such as fluency, coherence, and informativeness.\n",
        "- Semantic similarity metrics: Using metrics like BERTScore or BLEURT, which evaluate the semantic similarity between the generated summary and the reference summary, can provide a more comprehensive assessment of summarization quality.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "78b89a7a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.031008</td>\n",
              "      <td>0.031008</td>\n",
              "      <td>0.031008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.311491</td>\n",
              "      <td>0.311491</td>\n",
              "      <td>0.311491</td>\n",
              "      <td>0.311491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.203819</td>\n",
              "      <td>0.203819</td>\n",
              "      <td>0.203819</td>\n",
              "      <td>0.203819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.317425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.303855</td>\n",
              "      <td>0.368726</td>\n",
              "      <td>0.193333</td>\n",
              "      <td>0.193333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10101</td>\n",
              "      <td>0.158088</td>\n",
              "      <td>0.153535</td>\n",
              "      <td>0.153535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.125336</td>\n",
              "      <td>0.125336</td>\n",
              "      <td>0.125336</td>\n",
              "      <td>0.125336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.092037</td>\n",
              "      <td>0.224122</td>\n",
              "      <td>0.224122</td>\n",
              "      <td>0.224122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.251082</td>\n",
              "      <td>0.251082</td>\n",
              "      <td>0.251082</td>\n",
              "      <td>0.251082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.338828</td>\n",
              "      <td>0.503704</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0.157143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          1         2         3         4\n",
              "0  0.121212  0.031008  0.031008  0.031008\n",
              "1  0.311491  0.311491  0.311491  0.311491\n",
              "2  0.203819  0.203819  0.203819  0.203819\n",
              "3  0.051282  0.051282  0.051282  0.317425\n",
              "4  0.303855  0.368726  0.193333  0.193333\n",
              "5   0.10101  0.158088  0.153535  0.153535\n",
              "6  0.125336  0.125336  0.125336  0.125336\n",
              "7  0.092037  0.224122  0.224122  0.224122\n",
              "8  0.251082  0.251082  0.251082  0.251082\n",
              "9  0.338828  0.503704  0.157143  0.157143"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dataframe to store the results with different beam sizes\n",
        "beam_sizes = [1,2,3,4]\n",
        "beam_sizes_results = pd.DataFrame(columns=beam_sizes)\n",
        "max_length = 10\n",
        "num_samples = 10\n",
        "temperature = 1.0\n",
        "no_repeat_ngram_size = 3\n",
        "k = 5\n",
        "p = 0.9\n",
        "for beam in beam_sizes:\n",
        "    for i,sample in enumerate(dataset[:num_samples]):\n",
        "        \n",
        "        article = sample[\"article\"]\n",
        "        reference = sample[\"highlights\"]\n",
        "        generated = generate_summary_custom(article, strategy=\"beam\", max_length=max_length, temperature=temperature,k=k,p=p, beam_size=beam, no_repeat_ngram_size=no_repeat_ngram_size)\n",
        "        # generated = \"Students and faculty members marched Wednesday afternoon chanting\"\n",
        "        rouge1 = compute_rouge_n(reference, generated, n=1)[\"f1\"]\n",
        "        rouge2 = compute_rouge_n(reference, generated, n=2)[\"f1\"]\n",
        "        rougel = compute_rouge_l(reference, generated)[\"f1\"]\n",
        "        rouge_mean = (rouge1 + rouge2 + rougel) / 3\n",
        "        beam_sizes_results.loc[i, beam] = rouge_mean\n",
        "        beam_sizes_results.to_csv(\"beam_sizes_results.csv\", index=False) # save the results to a csv file\n",
        "        \n",
        "\n",
        "beam_sizes_results \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ddafb04d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2621713/1283966568.py:4: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(df.values, labels=df.columns)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create a boxplot to visualize different beam sizes\n",
        "df = pd.read_csv(\"beam_sizes_results.csv\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(df.values, labels=df.columns)\n",
        "plt.title(\"Mean ROUGE Scores (ROUGE-1, ROUGE-2, ROUG-L) for Different Beam Sizes\")\n",
        "plt.xlabel(\"Beam Size\")\n",
        "plt.ylabel(\"ROUGE Score\")\n",
        "plt.savefig(\"beam_sizes_results.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "47041e25",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.5</th>\n",
              "      <th>1.0</th>\n",
              "      <th>2.0</th>\n",
              "      <th>5.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.124031</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.279196</td>\n",
              "      <td>0.291775</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.203819</td>\n",
              "      <td>0.203819</td>\n",
              "      <td>0.031746</td>\n",
              "      <td>0.031008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.052288</td>\n",
              "      <td>0.284615</td>\n",
              "      <td>0.053333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.228333</td>\n",
              "      <td>0.228333</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.125336</td>\n",
              "      <td>0.116749</td>\n",
              "      <td>0.063492</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.093889</td>\n",
              "      <td>0.190159</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.258578</td>\n",
              "      <td>0.258578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.315018</td>\n",
              "      <td>0.555062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0.5       1.0       2.0       5.0\n",
              "0  0.124031  0.093023  0.033333       0.0\n",
              "1  0.279196  0.291775       0.0       0.0\n",
              "2  0.203819  0.203819  0.031746  0.031008\n",
              "3  0.052288  0.284615  0.053333       0.0\n",
              "4  0.228333  0.228333  0.051282       0.0\n",
              "5  0.104167       0.0  0.039216       0.0\n",
              "6  0.125336  0.116749  0.063492       0.0\n",
              "7  0.093889  0.190159       0.0       0.0\n",
              "8  0.258578  0.258578       0.0       0.0\n",
              "9  0.315018  0.555062       0.0       0.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dataframe to store the results with different beam sizes\n",
        "temperatures = [0.5,1,2,5]\n",
        "temperatures_results = pd.DataFrame(columns=temperatures)\n",
        "max_length = 10\n",
        "num_samples = 10\n",
        "beam_size = 1.0\n",
        "no_repeat_ngram_size = 3\n",
        "k = 5\n",
        "p = 0.5\n",
        "for temperature in temperatures:\n",
        "    for i,sample in enumerate(dataset[:num_samples]):\n",
        "        \n",
        "        article = sample[\"article\"]\n",
        "        reference = sample[\"highlights\"]\n",
        "        generated = generate_summary_custom(article, strategy=\"top_p\", max_length=max_length, temperature=temperature,k=k,p=p, beam_size=beam_size, no_repeat_ngram_size=no_repeat_ngram_size)\n",
        "        # generated = \"Students and faculty members marched Wednesday afternoon chanting\"\n",
        "        rouge1 = compute_rouge_n(reference, generated, n=1)[\"f1\"]\n",
        "        rouge2 = compute_rouge_n(reference, generated, n=2)[\"f1\"]\n",
        "        rougel = compute_rouge_l(reference, generated)[\"f1\"]\n",
        "        rouge_mean = (rouge1 + rouge2 + rougel) / 3\n",
        "        temperatures_results.loc[i, temperature] = rouge_mean\n",
        "        temperatures_results.to_csv(\"temperatures_results.csv\", index=False) # save the results to a csv file\n",
        "        \n",
        "\n",
        "temperatures_results \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2825e02d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2621713/3977070997.py:4: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(df.values, labels=df.columns)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create a boxplot to visualize different beam sizes\n",
        "df = pd.read_csv(\"temperatures_results.csv\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(df.values, labels=df.columns)\n",
        "plt.title(\"Mean ROUGE Scores (ROUGE-1, ROUGE-2, ROUG-L) for Different Temperatures using Top-P method\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"ROUGE Score\")\n",
        "plt.savefig(\"temperatures_results.png\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
